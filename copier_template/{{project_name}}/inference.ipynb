{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "# For loading the full model, all dependency groups that were installed during training should be installed now\n",
    "pip install ./medicalmultitaskmodeling[api,detection,interactive] --extra-index https://gitlab.com/api/v4/groups/11254156/-/packages/pypi/simple\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as F\n",
    "from PIL import Image\n",
    "from albumentations.augmentations.geometric.functional import resize\n",
    "from mmm.labelstudio_ext.NativeBlocks import NativeBlocks, MMM_MODELS, DEFAULT_MODEL\n",
    "from mmm.interactive import tasks\n",
    "# We load the model from an archive,\n",
    "# which allows us to load only those modules that are compatible with the current environment.\n",
    "model = NativeBlocks(MMM_MODELS[DEFAULT_MODEL], device_identifier=\"cuda:0\")\n",
    "model.get_device(), model.get_task_keys()[:5], model.get_sharedblock_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio.v3 as imageio\n",
    "# Load an image from the web\n",
    "raw_image = imageio.imread(r\"https://owncloud.fraunhofer.de/index.php/s/n6gycdah9SaxOdD/download\")\n",
    "Image.fromarray(raw_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input should be divisible by 32 and similar to the pre-training setting.\n",
    "# For ImageNet, we trained with a static size of 256x256\n",
    "input_image = resize(raw_image, height=256, width=256, interpolation=cv2.INTER_LINEAR)\n",
    "# Inputs need to be between 0 and 1\n",
    "input_image = F.to_tensor(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    # The model expects batches\n",
    "    feature_pyramid = model[\"encoder\"](input_image.unsqueeze(0).to(model.device))\n",
    "    print([feature_map.shape for feature_map in feature_pyramid])\n",
    "    hidden_vector = nn.Flatten(1)(model[\"squeezer\"](feature_pyramid)[1])\n",
    "    print(hidden_vector.shape)\n",
    "    print(some_values := hidden_vector[0, :5].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to changes in hardware and version dependencies of the training environment, results may not be reproducible.\n",
    "Here we check if the current environment can load the given model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = [\n",
    "    x - y\n",
    "    for x, y in zip(\n",
    "        some_values,\n",
    "        [-0.16809800267219543, 0.8937981724739075, 0.1215958520770073, 0.2989726662635803, 0.02798079140484333],\n",
    "    )\n",
    "]\n",
    "if all(abs(difference) < 1e-6 for difference in differences):\n",
    "    print(f\"The reproducibility test passed! {differences=}\")\n",
    "else:\n",
    "    raise Exception(f\"The reproducibility test failed! {differences=}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we can perform inference with one of the pretraining tasks. The ImageNet classifier should classify the image of a teddy bear correctly as \"teddy, teddy bear\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtl_task: tasks.ClassificationTask = model['imgnetclf']\n",
    "imagenet_classnames = mtl_task.class_names.copy()\n",
    "\n",
    "# You can use the representation for classification. \n",
    "scores = nn.Softmax(dim=1)(mtl_task.task_modules[\"classification_head\"](hidden_vector).detach().cpu())\n",
    "# Print the top classes\n",
    "print([(imagenet_classnames[i], scores[0, i].item()) for i in torch.argsort(scores, descending=True)[0, :5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (highest_class := imagenet_classnames[torch.argmax(scores).item()]) == \"teddy, teddy bear\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
